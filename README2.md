# Установка
Перед запуском скрипта.     

    pip install -r requirements.txt

# Как это работает?
    Как-то.
В целом. Алгоритм работы простой, если это вообще можно назвать алгоритмом.
Я просто заходил на информационные ресурсы, просмотривая, где находится основная информация на них,
после чего просто вписывал данные в cfg.py(файл настройки).
HTML-код парсил с помощью BeautifulSoup, а сам html доставал с помощью Requests.

Помимо этого здесь есть "КЛАСС" работы с текстом, а также его форматирующий, но
его наличие в программе на данном этапе бессмысленно :с

# Файлы.
    main.cpp    - сама программа
    cfg.py      - файл настройки
                  В нём можно изменить ширину строки, а также добавить нужные Вам сайты.
    format.py   - файл с классом Format
    save_txt.py - в разработке. В теории это должно быть решением первого усложениния.
    
# Направление дальнейшего улучшения/развития программы.
1.      Нужно таки разобраться с ссылками в тексте. Просто убирать их - не
        решение задачи, но и оставлять их невыгодно, если мы хотим получить ширину
        строки меньше "width", поэтому лучше заменить каждую ссылку на [{i}], а после
        текста оставить блок ссылок вида:
            [{1}] : http://...
            [{2}] : https://...
            [{3}] : http://...
        Иначе сделать так, как сказано в условии задачи.
    
2.1     Стоит расширить количество поддерживаемых сайтов..

2.2     Естественно, при увеличении сайтов пользователю будет некомфортно искать номер
        нужного ему, поэтому стоит избавить его от сей проблемы. Вполне себе реализуемо 
        одним словарём
      
(2.0)   Но лучше таки понять, как сделать универсальный алгоритм..
        Вполне себе можно взять идеи у обычных Reader-View программ, которые
        смотрят все "h1", "h2", "h3", "p", после чего просто вытаскивать из них все строки,
        длина которых превышает ХОТЯ БЫ 20.
      
3.     Возможно всё-таки стоит использовать больше классов, хотя и абстрактных..
